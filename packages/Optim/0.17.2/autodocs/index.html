<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings Â· Optim.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Optim.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Readme</a></li><li class="current"><a class="toctext" href>Docstrings</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Docstrings</a></li></ul></nav><hr/><div id="topbar"><span>Docstrings</span><a class="fa fa-bars" href="#"></a></div></header><pre><code class="language-none">Optim.@add_linesearch_fields</code></pre><pre><code class="language-none">Optim.@brenttrace</code></pre><pre><code class="language-none">Optim.@def</code></pre><pre><code class="language-none">Optim.@goldensectiontrace</code></pre><pre><code class="language-none">Optim.@initial_linesearch</code></pre><pre><code class="language-none">Optim.@pack_SAMIN</code></pre><pre><code class="language-none">Optim.@pack_SAMIN!</code></pre><pre><code class="language-none">Optim.@unpack_SAMIN</code></pre><pre><code class="language-none">Optim.AbstractBarrierState</code></pre><pre><code class="language-none">Optim.AbstractConstrainedOptimizer</code></pre><pre><code class="language-none">Optim.AbstractNGMRES</code></pre><pre><code class="language-none">Optim.AbstractOptimizer</code></pre><pre><code class="language-none">Optim.AbstractOptimizerState</code></pre><pre><code class="language-none">Optim.AcceleratedGradientDescent</code></pre><pre><code class="language-none">Optim.AcceleratedGradientDescentState</code></pre><pre><code class="language-none">Optim.AdaptiveParameters</code></pre><pre><code class="language-none">Optim.AffineSimplexer</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.BFGS" href="#Optim.BFGS"><code>Optim.BFGS</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>BFGS</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">BFGS(; alphaguess = LineSearches.InitialStatic(),
       linesearch = LineSearches.HagerZhang(),
       initial_invH = x -&gt; Matrix{eltype(x)}(I, length(x), length(x)),
       manifold = Flat())</code></pre><p><strong>Description</strong></p><p>The <code>BFGS</code> method implements the Broyden-Fletcher-Goldfarb-Shanno algorithm as described in Nocedal and Wright (sec. 8.1, 1999) and the four individual papers Broyden (1970), Fletcher (1970), Goldfarb (1970), and Shanno (1970). It is a quasi-Newton method that updates an approximation to the Hessian using past approximations as well as the gradient. See also the limited memory variant <code>LBFGS</code> for an algorithm that is more suitable for high dimensional problems.</p><p><strong>References</strong></p><ul><li>Wright, S. J. and J. Nocedal (1999), Numerical optimization. Springer Science 35.67-68: 7.</li><li>Broyden, C. G. (1970), The convergence of a class of double-rank minimization algorithms, Journal of the Institute of Mathematics and Its Applications, 6: 76â€“90.</li><li>Fletcher, R. (1970), A New Approach to Variable Metric Algorithms, Computer Journal, 13 (3): 317â€“322,</li><li>Goldfarb, D. (1970), A Family of Variable Metric Updates Derived by Variational Means, Mathematics of Computation, 24 (109): 23â€“26,</li><li>Shanno, D. F. (1970), Conditioning of quasi-Newton methods for function minimization, Mathematics of Computation, 24 (111): 647â€“656.</li></ul></div></div></section><pre><code class="language-none">Optim.BFGSState</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.BarrierLineSearch" href="#Optim.BarrierLineSearch"><code>Optim.BarrierLineSearch</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">BarrierLineSearch{T}</code></pre><p>Parameters for interior-point line search methods that use only the value</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.BarrierLineSearchGrad" href="#Optim.BarrierLineSearchGrad"><code>Optim.BarrierLineSearchGrad</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">BarrierLineSearchGrad{T}</code></pre><p>Parameters for interior-point line search methods that exploit the slope.</p></div></div></section><pre><code class="language-none">Optim.BarrierStateVars</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.Brent" href="#Optim.Brent"><code>Optim.Brent</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>Brent</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">    Brent(;)</code></pre><p><strong>Description</strong></p><p>Also known as the Brent-Dekker algorith, <code>Brent</code> is a univariate optimization algorithm for minimizing functions on some interval <code>[a,b]</code>. The method uses bisection to find a zero of the gradient. If the original interval contains a minimum, bisection will reliably find the solution, but can be slow. To this end <code>Brent</code> combines bisection with the secant method and inverse quadratic interpolation to accelerate convergence.</p><p><strong>References</strong></p><p>R. P. Brent (2002) Algorithms for Minimization Without Derivatives. Dover edition.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.ConjugateGradient" href="#Optim.ConjugateGradient"><code>Optim.ConjugateGradient</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>Conjugate Gradient Descent</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">ConjugateGradient(; alphaguess = LineSearches.InitialHagerZhang(),
linesearch = LineSearches.HagerZhang(),
eta = 0.4,
P = nothing,
precondprep = (P, x) -&gt; nothing,
manifold = Flat())</code></pre><p>The strictly positive constant <span>$eta$</span> is used in determining the next step direction, and the default here deviates from the one used in the original paper (where it was <span>$0.01$</span>). See more details in the original papers referenced below.</p><p><strong>Description</strong></p><p>The <code>ConjugateGradient</code> method implements Hager and Zhang (2006) and elements from Hager and Zhang (2013). Notice, the default <code>linesearch</code> is <code>HagerZhang</code> from LineSearches.jl. This line search is exactly the one proposed in Hager and Zhang (2006).</p><p><strong>References</strong></p><ul><li>W. W. Hager and H. Zhang (2006) Algorithm 851: CG_DESCENT, a conjugate gradient method with guaranteed descent. ACM Transactions on Mathematical Software 32: 113-137.</li><li>W. W. Hager and H. Zhang (2013), The Limited Memory Conjugate Gradient Method. SIAM Journal on Optimization, 23, pp. 2150-2168.</li></ul></div></div></section><pre><code class="language-none">Optim.ConjugateGradientState</code></pre><pre><code class="language-none">Optim.ConstrainedOptimizer</code></pre><pre><code class="language-none">Optim.FirstOrderOptimizer</code></pre><pre><code class="language-none">Optim.FixedParameters</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.Flat" href="#Optim.Flat"><code>Optim.Flat</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p>Flat Euclidean space {R,C}^N, with projections equal to the identity.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.Fminbox" href="#Optim.Fminbox"><code>Optim.Fminbox</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>Fminbox</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">Fminbox(method::T,
        mu0::Tf
        mufactor::Tf
        precondprep::P)</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.GoldenSection" href="#Optim.GoldenSection"><code>Optim.GoldenSection</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>GoldenSection</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">    GoldenSection(;)</code></pre><p><strong>Description</strong></p><p>The <code>GoldenSection</code> method seeks to minimize a univariate function on an interval <code>[a, b]</code>. At all times the algorithm maintains a tuple of three minimizer candidates <code>(c, d, e)</code> where <span>$c&lt;d&lt;e$</span> such that the ratio of the largest to the smallest interval is the Golden Ratio.</p><p><strong>References</strong></p><p>https://en.wikipedia.org/wiki/Golden-section_search</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.GradientDescent" href="#Optim.GradientDescent"><code>Optim.GradientDescent</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>Gradient Descent</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">GradientDescent(; alphaguess = LineSearches.InitialHagerZhang(),
linesearch = LineSearches.HagerZhang(),
P = nothing,
precondprep = (P, x) -&gt; nothing)</code></pre><p>Keywords are used to control choice of line search, and preconditioning.</p><p><strong>Description</strong></p><p>The <code>GradientDescent</code> method a simple gradient descent algorithm, that is the search direction is simply the negative gradient at the current iterate, and then a line search step is used to compute the final step. See Nocedal and Wright (ch. 2.2, 1999) for an explanation of the approach.</p><p><strong>References</strong></p><ul><li>Nocedal, J. and Wright, S. J. (1999), Numerical optimization. Springer Science 35.67-68: 7.</li></ul></div></div></section><pre><code class="language-none">Optim.GradientDescentState</code></pre><pre><code class="language-none">Optim.Hf</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.IPNewton" href="#Optim.IPNewton"><code>Optim.IPNewton</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>Interior-point Newton</strong></p><p><strong>Constructor</strong></p><pre><code class="language-jl">IPNewton(; linesearch::Function = Optim.backtrack_constrained_grad,
         Î¼0::Union{Symbol,Number} = :auto,
         show_linesearch::Bool = false)</code></pre><p>The initial barrier penalty coefficient <code>Î¼0</code> can be chosen as a number, or set to <code>:auto</code> to let the algorithm decide its value, see <code>initialize_Î¼_Î»!</code>.</p><p><em>Note</em>: For constrained optimization problems, we recommend always enabling <code>allow_f_increases</code> and <code>successive_f_tol</code> in the options passed to <code>optimize</code>. The default is set to <code>Optim.Options(allow_f_increases = true, successive_f_tol = 2)</code>.</p><p>As of February 2018, the line search algorithm is specialised for constrained interior-point methods. In future we hope to support more algorithms from <code>LineSearches.jl</code>.</p><p><strong>Description</strong></p><p>The <code>IPNewton</code> method implements an interior-point primal-dual Newton algorithm for solving nonlinear, constrained optimization problems. See Nocedal and Wright (Ch. 19, 2006) for a discussion of interior-point methods for constrained optimization.</p><p><strong>References</strong></p><p>The algorithm was <a href="https://github.com/JuliaNLSolvers/Optim.jl/pull/303">originally written by Tim Holy</a> (@timholy, tim.holy@gmail.com).</p><ul><li>J Nocedal, SJ Wright (2006), Numerical optimization, second edition. Springer.</li><li>A WÃ¤chter, LT Biegler (2006), On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming. Mathematical Programming 106 (1), 25-57.</li></ul></div></div></section><pre><code class="language-none">Optim.IPNewtonState</code></pre><pre><code class="language-none">Optim.IPOptimizer</code></pre><pre><code class="language-none">Optim.InverseDiagonal</code></pre><pre><code class="language-none">Optim.KrylovTrustRegion</code></pre><pre><code class="language-none">Optim.KrylovTrustRegionState</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.LBFGS" href="#Optim.LBFGS"><code>Optim.LBFGS</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>LBFGS</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">LBFGS(; m::Integer = 10,
alphaguess = LineSearches.InitialStatic(),
linesearch = LineSearches.HagerZhang(),
P=nothing,
precondprep = (P, x) -&gt; nothing,
manifold = Flat(),
scaleinvH0::Bool = true &amp;&amp; (typeof(P) &lt;: Nothing))</code></pre><p><code>LBFGS</code> has two special keywords; the memory length <code>m</code>, and the <code>scaleinvH0</code> flag. The memory length determines how many previous Hessian approximations to store. When <code>scaleinvH0 == true</code>, then the initial guess in the two-loop recursion to approximate the inverse Hessian is the scaled identity, as can be found in Nocedal and Wright (2nd edition) (sec. 7.2).</p><p>In addition, LBFGS supports preconditioning via the <code>P</code> and <code>precondprep</code> keywords.</p><p><strong>Description</strong></p><p>The <code>LBFGS</code> method implements the limited-memory BFGS algorithm as described in Nocedal and Wright (sec. 7.2, 2006) and original paper by Liu &amp; Nocedal (1989). It is a quasi-Newton method that updates an approximation to the Hessian using past approximations as well as the gradient.</p><p><strong>References</strong></p><ul><li>Wright, S. J. and J. Nocedal (2006), Numerical optimization, 2nd edition. Springer</li><li>Liu, D. C. and Nocedal, J. (1989). &quot;On the Limited Memory Method for Large Scale Optimization&quot;. Mathematical Programming B. 45 (3): 503â€“528</li></ul></div></div></section><pre><code class="language-none">Optim.LBFGSState</code></pre><pre><code class="language-none">Optim.Manifold</code></pre><pre><code class="language-none">Optim.ManifoldObjective</code></pre><pre><code class="language-none">Optim.MaximizationWrapper</code></pre><pre><code class="language-none">Optim.MomentumGradientDescent</code></pre><pre><code class="language-none">Optim.MomentumGradientDescentState</code></pre><pre><code class="language-none">Optim.MultivariateOptimizationResults</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.NGMRES" href="#Optim.NGMRES"><code>Optim.NGMRES</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>N-GMRES</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">NGMRES(;
        alphaguess = LineSearches.InitialStatic(),
        linesearch = LineSearches.HagerZhang(),
        manifold = Flat(),
        wmax::Int = 10,
        Ïµ0 = 1e-12,
        nlprecon = GradientDescent(
            alphaguess = LineSearches.InitialStatic(alpha=1e-4,scaled=true),
            linesearch = LineSearches.Static(),
            manifold = manifold),
        nlpreconopts = Options(iterations = 1, allow_f_increases = true),
      )</code></pre><p><strong>Description</strong></p><p>This algorithm takes a step given by the nonlinear preconditioner <code>nlprecon</code> and proposes an accelerated step by minimizing an approximation of the (ll_2) residual of the gradient on a subspace spanned by the previous <code>wmax</code> iterates.</p><p>N-GMRES was originally developed for solving nonlinear systems [1], and reduces to GMRES for linear problems. Application of the algorithm to optimization is covered, for example, in [2].</p><p><strong>References</strong></p><p>[1] De Sterck. Steepest descent preconditioning for nonlinear GMRES optimization. NLAA, 2013. [2] Washio and Oosterlee. Krylov subspace acceleration for nonlinear multigrid schemes. ETNA, 1997.</p></div></div></section><pre><code class="language-none">Optim.NGMRESState</code></pre><pre><code class="language-none">Optim.NMParameters</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.NelderMead" href="#Optim.NelderMead"><code>Optim.NelderMead</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>NelderMead</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">NelderMead(; parameters = AdaptiveParameters(),
             initial_simplex = AffineSimplexer())</code></pre><p>The constructor takes 2 keywords:</p><ul><li><code>parameters</code>, an instance of either <code>AdaptiveParameters</code> or <code>FixedParameters</code>,</li></ul><p>and is used to generate parameters for the Nelder-Mead Algorithm</p><ul><li><code>initial_simplex</code>, an instance of <code>AffineSimplexer</code></li></ul><p><strong>Description</strong></p><p>Our current implementation of the Nelder-Mead algorithm is based on [1] and [3]. Gradient-free methods can be a bit sensitive to starting values and tuning parameters, so it is a good idea to be careful with the defaults provided in Optim.jl.</p><p>Instead of using gradient information, Nelder-Mead is a direct search method. It keeps track of the function value at a number of points in the search space. Together, the points form a simplex. Given a simplex, we can perform one of four actions: reflect, expand, contract, or shrink. Basically, the goal is to iteratively replace the worst point with a better point. More information can be found in [1], [2] or [3].</p><p><strong>References</strong></p><ul><li>[1] Nelder, John A. and R. Mead (1965). &quot;A simplex method for function minimization&quot;. Computer Journal 7: 308â€“313. doi:10.1093/comjnl/7.4.308</li><li>[2] Lagarias, Jeffrey C., et al. &quot;Convergence properties of the Nelderâ€“Mead simplex method in low dimensions.&quot; SIAM Journal on Optimization 9.1 (1998): 112-147</li><li>[3] Gao, Fuchang and Lixing Han (2010). &quot;Implementing the Nelder-Mead simplex algorithm with adaptive parameters&quot;. Computational Optimization and Applications. doi:10.1007/s10589-010-9329-3</li></ul></div></div></section><pre><code class="language-none">Optim.NelderMeadState</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.Newton" href="#Optim.Newton"><code>Optim.Newton</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>Newton</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">Newton(; alphaguess = LineSearches.InitialStatic(),
linesearch = LineSearches.HagerZhang())</code></pre><p><strong>Description</strong></p><p>The <code>Newton</code> method implements Newton&#39;s method for optimizing a function. We use a special factorization from the package <code>PositiveFactorizations.jl</code> to ensure that each search direction is a direction of descent. See Wright and Nocedal and Wright (ch. 6, 1999) for a discussion of Newton&#39;s method in practice.</p><p><strong>References</strong></p><ul><li>Nocedal, J. and S. J. Wright (1999), Numerical optimization. Springer Science 35.67-68: 7.</li></ul></div></div></section><pre><code class="language-none">Optim.NewtonState</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.NewtonTrustRegion" href="#Optim.NewtonTrustRegion"><code>Optim.NewtonTrustRegion</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>NewtonTrustRegion</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">NewtonTrustRegion(; initial_delta = 1.0,
                    delta_hat = 100.0,
                    eta = 0.1,
                    rho_lower = 0.25,
                    rho_upper = 0.75)</code></pre><p>The constructor has 5 keywords:</p><ul><li><code>initial_delta</code>, the starting trust region radius</li><li><code>delta_hat</code>, the largest allowable trust region radius</li><li><code>eta</code>, when <code>rho</code> is at least <code>eta</code>, accept the step</li><li><code>rho_lower</code>, when <code>rho</code> is less than <code>rho_lower</code>, shrink the trust region</li><li><code>rho_upper</code>, when <code>rho</code> is greater than <code>rho_upper</code>, grow the trust region</li></ul><p><strong>Description</strong></p><p>The <code>NewtonTrustRegion</code> method implements Newton&#39;s method with a trust region for optimizing a function. The method is designed to take advantage of the second-order information in a function&#39;s Hessian, but with more stability that Newton&#39;s method when functions are not globally well-approximated by a quadratic. This is achieved by repeatedly minimizing quadratic approximations within a dynamically-sized trust region in which the function is assumed to be locally quadratic. See Wright and Nocedal and Wright (ch. 4, 1999) for a discussion of trust-region methods in practice.</p><p><strong>References</strong></p><ul><li>Nocedal, J. and S. J. Wright (1999), Numerical optimization. Springer Science 35.67-68: 7.</li></ul></div></div></section><pre><code class="language-none">Optim.NewtonTrustRegionState</code></pre><pre><code class="language-none">Optim.NonDifferentiable</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.OACCEL" href="#Optim.OACCEL"><code>Optim.OACCEL</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>O-ACCEL</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">OACCEL(;manifold::Manifold = Flat(),
       alphaguess = LineSearches.InitialStatic(),
       linesearch = LineSearches.HagerZhang(),
       nlprecon = GradientDescent(
           alphaguess = LineSearches.InitialStatic(alpha=1e-4,scaled=true),
           linesearch = LineSearches.Static(),
           manifold = manifold),
       nlpreconopts = Options(iterations = 1, allow_f_increases = true),
       Ïµ0 = 1e-12,
       wmax::Int = 10)</code></pre><p><strong>Description</strong></p><p>This algorithm takes a step given by the nonlinear preconditioner <code>nlprecon</code> and proposes an accelerated step by minimizing an approximation of the objective on a subspace spanned by the previous <code>wmax</code> iterates.</p><p>O-ACCEL is a slight tweak of N-GMRES, first presented in [1].</p><p><strong>References</strong></p><p>[1] Riseth. Objective acceleration for unconstrained optimization. 2018.</p></div></div></section><pre><code class="language-none">Optim.OnceDifferentiable</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.Optim" href="#Optim.Optim"><code>Optim.Optim</code></a> â€” <span class="docstring-category">Module</span>.</div><div><div><p><strong>Optim.jl</strong></p><p>Welcome to Optim.jl!</p><p>Optim.jl is a package used to solve continuous optimization problems. It is written in Julia for Julians to help take advantage of arbitrary number types, fast computation, and excellent automatic differentiation tools.</p><p><strong>REPL help</strong></p><p><code>?</code> followed by an algorithm name (<code>?BFGS</code>), constructors (<code>?Optim.Options</code>) prints help to the terminal.</p><p><strong>Documentation</strong></p><p>Besides the help provided at the REPL, it is possible to find help and general documentation online at http://julianlsolvers.github.io/Optim.jl/stable/ .</p></div></div></section><pre><code class="language-none">Optim.OptimizationResults</code></pre><pre><code class="language-none">Optim.OptimizationState</code></pre><pre><code class="language-none">Optim.OptimizationTrace</code></pre><pre><code class="language-none">Optim.Options</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.ParticleSwarm" href="#Optim.ParticleSwarm"><code>Optim.ParticleSwarm</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>Particle Swarm</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">ParticleSwarm(; lower = [],
                upper = [],
                n_particles = 0)</code></pre><p>The constructor takes 3 keywords:</p><ul><li><code>lower = []</code>, a vector of lower bounds, unbounded below if empty or <code>Inf</code>&#39;s</li><li><code>upper = []</code>, a vector of upper bounds, unbounded above if empty or <code>Inf</code>&#39;s</li><li><code>n_particles = 0</code>, the number of particles in the swarm, defaults to least three</li></ul><p><strong>Description</strong></p><p>The Particle Swarm implementation in Optim.jl is the so-called Adaptive Particle Swarm algorithm in [1]. It attempts to improve global coverage and convergence by switching between four evolutionary states: exploration, exploitation, convergence, and jumping out. In the jumping out state it intentially tries to take the best particle and move it away from its (potentially and probably) local optimum, to improve the ability to find a global optimum. Of course, this comes a the cost of slower convergence, but hopefully converges to the global optimum as a result.</p><p><strong>References</strong></p><ul><li>[1] Zhan, Zhang, and Chung. Adaptive particle swarm optimization, IEEE Transactions on Systems, Man, and Cybernetics, Part B: CyberneticsVolume 39, Issue 6 (2009): 1362-1381</li></ul></div></div></section><pre><code class="language-none">Optim.ParticleSwarmState</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.PowerManifold" href="#Optim.PowerManifold"><code>Optim.PowerManifold</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p>Multiple copies of the same manifold. Points are stored as inner<em>dims x outer</em>dims, e.g. the product of 2x2 Stiefel manifolds of dimension N x n would be a N x n x 2 x 2 matrix.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.ProductManifold" href="#Optim.ProductManifold"><code>Optim.ProductManifold</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p>Product of two manifolds {P = (x1,x2), x1 âˆˆ m1, x2 âˆˆ m2}. P is stored as a flat 1D array, and x1 is before x2 in memory. Use get_inner(m, x, {1,2}) to access x1 or x2 in their original format.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.SAMIN" href="#Optim.SAMIN"><code>Optim.SAMIN</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>SAMIN</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">SAMIN(; nt::Int = 5     # reduce temperature every nt*ns*dim(x_init) evaluations
        ns::Int = 5     # adjust bounds every ns*dim(x_init) evaluations
        rt::T = 0.9     # geometric temperature reduction factor: when temp changes, new temp is t=rt*t
        neps::Int = 5   # number of previous best values the final result is compared to
        f_tol::T = 1e-12 # the required tolerance level for function value comparisons
        x_tol::T = 1e-6 # the required tolerance level for x
        coverage_ok::Bool = false, # if false, increase temperature until initial parameter space is covered
        verbosity::Int = 1) # scalar: 0, 1, 2 or 3 (default = 1).</code></pre><p><strong>Description</strong></p><p>The <code>SAMIN</code> method implements the Simulated Annealing algorithm for problems with bounds constrains a described in Goffe et. al. (1994) and Goffe (1996). The algorithm</p><p><strong>References</strong></p><ul><li>Goffe, et. al. (1994) &quot;Global Optimization of Statistical Functions with Simulated Annealing&quot;, Journal of Econometrics, V. 60, N. 1/2.</li><li>Goffe, William L. (1996) &quot;SIMANN: A Global Optimization Algorithm using Simulated Annealing &quot; Studies in Nonlinear Dynamics &amp; Econometrics, Oct96, Vol. 1 Issue 3.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaLang/julia/blob/80516ca20297a67b996caa08c38786332379b6a5/base/#L0-L21">source</a></section><pre><code class="language-none">Optim.SecondOrderOptimizer</code></pre><pre><code class="language-none">Optim.Simplexer</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.SimulatedAnnealing" href="#Optim.SimulatedAnnealing"><code>Optim.SimulatedAnnealing</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p><strong>SimulatedAnnealing</strong></p><p><strong>Constructor</strong></p><pre><code class="language-julia">SimulatedAnnealing(; neighbor = default_neighbor!,
                     temperature = log_temperature,
                     keep_best::Bool = true)</code></pre><p>The constructor takes 3 keywords:</p><ul><li><code>neighbor = a!(x_proposed, x_current)</code>, a mutating function of the current <code>x</code>,</li></ul><p>and the proposed <code>x</code></p><ul><li><code>T = b(iteration)</code>, a function of the current iteration that returns a temperature</li><li><code>p = c(f_proposal, f_current, T)</code>, a function of the current temperature, current</li></ul><p>function value and proposed function value that returns an acceptance probability</p><p><strong>Description</strong></p><p>Simulated Annealing is a derivative free method for optimization. It is based on the Metropolis-Hastings algorithm that was originally used to generate samples from a thermodynamics system, and is often used to generate draws from a posterior when doing Bayesian inference. As such, it is a probabilistic method for finding the minimum of a function, often over a quite large domains. For the historical reasons given above, the algorithm uses terms such as cooling, temperature, and acceptance probabilities.</p></div></div></section><pre><code class="language-none">Optim.SimulatedAnnealingState</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.Sphere" href="#Optim.Sphere"><code>Optim.Sphere</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p>Spherical manifold {|x| = 1}.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.Stiefel" href="#Optim.Stiefel"><code>Optim.Stiefel</code></a> â€” <span class="docstring-category">Type</span>.</div><div><div><p>N x n matrices with orthonormal columns, i.e. such that X&#39;X = I. Special cases: N x 1 = sphere, N x N = orthogonal/unitary group. Stiefel() uses a SVD algorithm to compute the retraction. To use a Cholesky-based orthogonalization (faster but less stable), use Stiefel(:CholQR). When the function to be optimized depends only on the subspace X*X&#39; spanned by a point X in the Stiefel manifold, first-order optimization algorithms are equivalent for the Stiefel and Grassmann manifold, so there is no separate Grassmann manifold.</p></div></div></section><pre><code class="language-none">Optim.Stiefel_CholQR</code></pre><pre><code class="language-none">Optim.Stiefel_SVD</code></pre><pre><code class="language-none">Optim.TwiceDifferentiable</code></pre><pre><code class="language-none">Optim.TwiceDifferentiableConstraints</code></pre><pre><code class="language-none">Optim.UnivariateOptimizationResults</code></pre><pre><code class="language-none">Optim.UnivariateOptimizer</code></pre><pre><code class="language-none">Optim.ZerothOrderOptimizer</code></pre><pre><code class="language-none">Optim.ZerothOrderState</code></pre><pre><code class="language-none">Optim._bv</code></pre><pre><code class="language-none">Optim._lagrangian_linefunc</code></pre><pre><code class="language-none">Optim._lagrangian_lineslope</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim._updateA!" href="#Optim._updateA!"><code>Optim._updateA!</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><p>Update storage A[i,j] for <code>NGMRES</code></p></div></div><div><div><p>Update storage A[i,j] for <code>OACCEL</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim._updateQ!" href="#Optim._updateQ!"><code>Optim._updateQ!</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><p>Update storage Q[i,j] and Q[j,i] for <code>NGMRES</code></p></div></div><div><div><p>Update storage Q[i,j] and Q[j,i] for <code>OACCEL</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim._updateb!" href="#Optim._updateb!"><code>Optim._updateb!</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><p>Update storage b[i] for <code>NGMRES</code></p></div></div><div><div><p>Update storage b[i] for <code>OACCEL</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim._updateÎ·" href="#Optim._updateÎ·"><code>Optim._updateÎ·</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><p>Update value Î· for <code>NGMRES</code></p></div></div><div><div><p>Update value Î· for <code>OACCEL</code></p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim._updateÎ¾!" href="#Optim._updateÎ¾!"><code>Optim._updateÎ¾!</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><p>Update storage Î¾[i,:] for <code>NGMRES</code></p></div></div><div><div><p>Update storage Î¾[i,:] for <code>OACCEL</code></p></div></div></section><pre><code class="language-none">Optim.abs_tol</code></pre><pre><code class="language-none">Optim.add_default_opts!</code></pre><pre><code class="language-none">Optim.after_while!</code></pre><pre><code class="language-none">Optim.alphax</code></pre><pre><code class="language-none">Optim.assess_convergence</code></pre><pre><code class="language-none">Optim.backtrack_constrained</code></pre><pre><code class="language-none">Optim.backtrack_constrained_grad</code></pre><pre><code class="language-none">Optim.barrier_box</code></pre><pre><code class="language-none">Optim.barrier_combined</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.barrier_grad!" href="#Optim.barrier_grad!"><code>Optim.barrier_grad!</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">barrier_grad!(bgrad, bounds, x, bstate, Î¼)
barrier_grad!(gsx, gsc, bounds, x, sx, sc, Î¼)</code></pre><p>Compute the gradient of the barrier penalty at (<code>x</code>,<code>sx</code>,<code>sc</code>), where <code>x</code> is the current position, <code>sx</code> are the coordinate slack variables, and <code>sc</code> are the linear/nonlinear slack variables. <code>bounds::ConstraintBounds</code> holds the parsed bounds.</p><p>The result is <em>added</em> to <code>gsx</code>, and <code>gsc</code>, so these vectors need to be initialized appropriately.</p></div></div></section><pre><code class="language-none">Optim.barrier_method</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.barrier_value" href="#Optim.barrier_value"><code>Optim.barrier_value</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">barrier_value(constraints, state) -&gt; val
barrier_value(bounds, x, sx, sc, Î¼) -&gt; val</code></pre><p>Compute the value of the barrier penalty at the current <code>state</code>, or at a position (<code>x</code>,<code>sx</code>,<code>sc</code>), where <code>x</code> is the current position, <code>sx</code> are the coordinate slack variables, and <code>sc</code> are the linear/nonlinear slack variables. <code>bounds</code> holds the parsed bounds.</p></div></div></section><pre><code class="language-none">Optim.bsv_seed</code></pre><pre><code class="language-none">Optim.cE</code></pre><pre><code class="language-none">Optim.cbar</code></pre><pre><code class="language-none">Optim.centroid</code></pre><pre><code class="language-none">Optim.centroid!</code></pre><pre><code class="language-none">Optim.cg_steihaug!</code></pre><pre><code class="language-none">Optim.check_hard_case_candidate</code></pre><pre><code class="language-none">Optim.check_kwargs</code></pre><pre><code class="language-none">Optim.common_trace!</code></pre><pre><code class="language-none">Optim.compute_cost!</code></pre><pre><code class="language-none">Optim.constant_temperature</code></pre><pre><code class="language-none">Optim.converged</code></pre><pre><code class="language-none">Optim.default_convergence_assessment</code></pre><pre><code class="language-none">Optim.default_neighbor!</code></pre><pre><code class="language-none">Optim.default_options</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.equality_grad!" href="#Optim.equality_grad!"><code>Optim.equality_grad!</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">equality_grad!(gx, gbstate, bounds, x, c, J, bstate)</code></pre><p>Compute the gradient of <code>equality_violation</code>, storing the result in <code>gx</code> (an array) and <code>gbstate::BarrierStateVars</code>.</p></div></div></section><pre><code class="language-none">Optim.equality_grad_var!</code></pre><pre><code class="language-none">Optim.equality_grad_Î»!</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.equality_violation" href="#Optim.equality_violation"><code>Optim.equality_violation</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">equality_violation([f=identity], bounds, x, c, bstate) -&gt; val
equality_violation([f=identity], bounds, x, c, sx, sc, Î»x, Î»c, Î»xE, Î»cE) -&gt; val</code></pre><p>Compute the sum of <code>f(v_i)</code>, where <code>v_i = Î»_i*(target - observed)</code> measures the difference between the current state and the equality-constrained state. <code>bounds::ConstraintBounds</code> holds the parsed bounds. <code>x</code> is the current position, <code>sx</code> are the coordinate slack variables, and <code>sc</code> are the linear/nonlinear slack variables. <code>c</code> holds the values of the linear-nonlinear constraints, and the Î» arguments hold the Lagrange multipliers for <code>x</code>, <code>sx</code>, <code>sc</code>, and <code>c</code> respectively.</p></div></div></section><pre><code class="language-none">Optim.estimate_maxstep</code></pre><pre><code class="language-none">Optim.eval</code></pre><pre><code class="language-none">Optim.evalgrad</code></pre><pre><code class="language-none">Optim.evalhess</code></pre><pre><code class="language-none">Optim.f_abschange</code></pre><pre><code class="language-none">Optim.f_calls</code></pre><pre><code class="language-none">Optim.f_converged</code></pre><pre><code class="language-none">Optim.f_increased</code></pre><pre><code class="language-none">Optim.f_relchange</code></pre><pre><code class="language-none">Optim.f_tol</code></pre><pre><code class="language-none">Optim.f_trace</code></pre><pre><code class="language-none">Optim.fallback_method</code></pre><pre><code class="language-none">Optim.function_barrier</code></pre><pre><code class="language-none">Optim.g_calls</code></pre><pre><code class="language-none">Optim.g_converged</code></pre><pre><code class="language-none">Optim.g_norm_trace</code></pre><pre><code class="language-none">Optim.g_residual</code></pre><pre><code class="language-none">Optim.g_tol</code></pre><pre><code class="language-none">Optim.get_inner</code></pre><pre><code class="language-none">Optim.get_mu_1</code></pre><pre><code class="language-none">Optim.get_mu_2</code></pre><pre><code class="language-none">Optim.get_mu_3</code></pre><pre><code class="language-none">Optim.get_mu_4</code></pre><pre><code class="language-none">Optim.get_swarm_state</code></pre><pre><code class="language-none">Optim.gf</code></pre><pre><code class="language-none">Optim.gradient_convergence_assessment</code></pre><pre><code class="language-none">Optim.grid_search</code></pre><pre><code class="language-none">Optim.h_calls</code></pre><pre><code class="language-none">Optim.has_deprecated_fminbox</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.hessianI" href="#Optim.hessianI"><code>Optim.hessianI</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><p>hessianI(x, constraints, Î»cI, Î¼) -&gt; h</p><p>Compute the hessian at <code>x</code> of the <code>Î»cI</code>-weighted sum of user-supplied constraint functions for just the inequalities.  This also includes contributions from any variables with bounds at 0, since those do not cause introduction of a slack variable. Other (nonzero) box constraints do not contribute to <code>h</code>, because the hessian of <code>x_i</code> is zero. (They contribute indirectly via their slack variables.)</p></div></div></section><pre><code class="language-none">Optim.hessianI!</code></pre><pre><code class="language-none">Optim.hessian_projections</code></pre><pre><code class="language-none">Optim.housekeeping!</code></pre><pre><code class="language-none">Optim.include</code></pre><pre><code class="language-none">Optim.initial_convergence</code></pre><pre><code class="language-none">Optim.initial_mu</code></pre><pre><code class="language-none">Optim.initial_state</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.initialize_Î¼_Î»!" href="#Optim.initialize_Î¼_Î»!"><code>Optim.initialize_Î¼_Î»!</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">initialize_Î¼_Î»!(state, bounds, Î¼0=:auto, Î²=0.01)
initialize_Î¼_Î»!(state, bounds, (Hobj,HcI), Î¼0=:auto, Î²=0.01)</code></pre><p>Pick Î¼ and Î» to ensure that the equality constraints are satisfied locally (at the current <code>state.x</code>), and that the initial gradient including the barrier would be a descent direction for the problem without the barrier (Î¼ = 0). This ensures that the search isn&#39;t pushed out of the basin of the user-supplied initial guess.</p><p>Upon entry, the objective function gradient, constraint values, and constraint jacobian must be set in <code>state.g</code>, <code>state.c</code>, and <code>state.J</code> respectively. If you also wish to ensure that the projection of Hessian is minimally-perturbed along the initial gradient, supply the hessian of the objective (<code>Hobj</code>) and</p><pre><code class="language-none">HcI = âˆ‘_i (Ïƒ_i/s_i)âˆ‡âˆ‡ c_{Ii}</code></pre><p>for the constraints. This can be obtained as</p><pre><code class="language-none">HcI = hessianI(state.x, constraints, 1./state.slack_c)</code></pre><p>You can manually specify <code>Î¼</code> by supplying a numerical value for <code>Î¼0</code>. Whether calculated algorithmically or specified manually, the values of <code>Î»</code> are set using the chosen <code>Î¼</code>.</p></div></div></section><pre><code class="language-none">Optim.is_smaller_eps</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.isfeasible" href="#Optim.isfeasible"><code>Optim.isfeasible</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">isfeasible(constraints, state) -&gt; Bool
isfeasible(constraints, x, c) -&gt; Bool
isfeasible(constraints, x) -&gt; Bool
isfeasible(bounds, x, c) -&gt; Bool</code></pre><p>Return <code>true</code> if point <code>x</code> is feasible, given the <code>constraints</code> which specify bounds <code>lx</code>, <code>ux</code>, <code>lc</code>, and <code>uc</code>. <code>x</code> is feasible if</p><pre><code class="language-none">lx[i] &lt;= x[i] &lt;= ux[i]
lc[i] &lt;= c[i] &lt;= uc[i]</code></pre><p>for all possible <code>i</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.isinterior" href="#Optim.isinterior"><code>Optim.isinterior</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">isinterior(constraints, state) -&gt; Bool
isinterior(constraints, x, c) -&gt; Bool
isinterior(constraints, x) -&gt; Bool
isinterior(bounds, x, c) -&gt; Bool</code></pre><p>Return <code>true</code> if point <code>x</code> is on the interior of the allowed region, given the <code>constraints</code> which specify bounds <code>lx</code>, <code>ux</code>, <code>lc</code>, and <code>uc</code>. <code>x</code> is in the interior if</p><pre><code class="language-none">lx[i] &lt; x[i] &lt; ux[i]
lc[i] &lt; c[i] &lt; uc[i]</code></pre><p>for all possible <code>i</code>.</p></div></div></section><pre><code class="language-none">Optim.iteration_limit_reached</code></pre><pre><code class="language-none">Optim.iterations</code></pre><pre><code class="language-none">Optim.jacobianE</code></pre><pre><code class="language-none">Optim.jacobianI</code></pre><pre><code class="language-none">Optim.jacobianx</code></pre><pre><code class="language-none">Optim.lagrangian</code></pre><pre><code class="language-none">Optim.lagrangian_fg!</code></pre><pre><code class="language-none">Optim.lagrangian_fgvec!</code></pre><pre><code class="language-none">Optim.lagrangian_linefunc</code></pre><pre><code class="language-none">Optim.lagrangian_linefunc!</code></pre><pre><code class="language-none">Optim.lagrangian_lineslope</code></pre><pre><code class="language-none">Optim.lagrangian_lineslope!</code></pre><pre><code class="language-none">Optim.lagrangian_vec</code></pre><pre><code class="language-none">Optim.lambdaE</code></pre><pre><code class="language-none">Optim.lambdaI</code></pre><pre><code class="language-none">Optim.limit_X!</code></pre><pre><code class="language-none">Optim.limits_box</code></pre><pre><code class="language-none">Optim.linesearch_anon</code></pre><pre><code class="language-none">Optim.log_temperature</code></pre><pre><code class="language-none">Optim.loginf</code></pre><pre><code class="language-none">Optim.lower_bound</code></pre><pre><code class="language-none">Optim.ls_update!</code></pre><pre><code class="language-none">Optim.maxdiff</code></pre><pre><code class="language-none">Optim.maximize</code></pre><pre><code class="language-none">Optim.maximizer</code></pre><pre><code class="language-none">Optim.method</code></pre><pre><code class="language-none">Optim.minimizer</code></pre><pre><code class="language-none">Optim.minimum</code></pre><pre><code class="language-none">Optim.mulhess</code></pre><pre><code class="language-none">Optim.ngmres_oaccel_warned</code></pre><pre><code class="language-none">Optim.nlprecon_post_accelerate!</code></pre><pre><code class="language-none">Optim.nlprecon_post_optimize!</code></pre><pre><code class="language-none">Optim.nmobjective</code></pre><pre><code class="language-none">Optim.optimize</code></pre><pre><code class="language-none">Optim.p_sq_norm</code></pre><pre><code class="language-none">Optim.pack_vec</code></pre><pre><code class="language-none">Optim.pack_vec!</code></pre><pre><code class="language-none">Optim.parameters</code></pre><pre><code class="language-none">Optim.perform_linesearch!</code></pre><pre><code class="language-none">Optim.pick_best_f</code></pre><pre><code class="language-none">Optim.pick_best_x</code></pre><pre><code class="language-none">Optim.precondprep!</code></pre><pre><code class="language-none">Optim.precondprepbox!</code></pre><pre><code class="language-none">Optim.print_header</code></pre><pre><code class="language-none">Optim.project_tangent</code></pre><pre><code class="language-none">Optim.project_tangent!</code></pre><pre><code class="language-none">Optim.promote_objtype</code></pre><pre><code class="language-none">Optim.qrregularize!</code></pre><pre><code class="language-none">Optim.rel_tol</code></pre><pre><code class="language-none">Optim.res</code></pre><pre><code class="language-none">Optim.reset_search_direction!</code></pre><pre><code class="language-none">Optim.retract</code></pre><pre><code class="language-none">Optim.retract!</code></pre><pre><code class="language-none">Optim.setslack!</code></pre><pre><code class="language-none">Optim.sigma</code></pre><pre><code class="language-none">Optim.simplexer</code></pre><pre><code class="language-none">Optim.slack</code></pre><pre><code class="language-none">Optim.slopealpha</code></pre><pre><code class="language-none">Optim.solve_slack!</code></pre><pre><code class="language-none">Optim.solve_step!</code></pre><pre><code class="language-none">Optim.solve_tr_subproblem!</code></pre><pre><code class="language-none">Optim.trace</code></pre><pre><code class="language-none">Optim.trace!</code></pre><pre><code class="language-none">Optim.twoloop!</code></pre><pre><code class="language-none">Optim.unpack_vec!</code></pre><pre><code class="language-none">Optim.update!</code></pre><pre><code class="language-none">Optim.update_fg!</code></pre><pre><code class="language-none">Optim.update_g!</code></pre><pre><code class="language-none">Optim.update_gtilde!</code></pre><pre><code class="language-none">Optim.update_h!</code></pre><pre><code class="language-none">Optim.update_state!</code></pre><pre><code class="language-none">Optim.update_swarm!</code></pre><pre><code class="language-none">Optim.update_swarm_params!</code></pre><pre><code class="language-none">Optim.upper_bound</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Optim.userÎ»" href="#Optim.userÎ»"><code>Optim.userÎ»</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">userÎ»(Î»cI, bounds) -&gt; Î»</code></pre><p>Accumulates <code>Î»cI</code> into a vector <code>Î»</code> ordered as the user-supplied constraint functions <code>c</code>. Upper and lower bounds are summed, weighted by <code>Ïƒ</code>. The resulting Î» includes an overall negative sign so that this becomes the coefficient for the user-supplied hessian.</p><p>This is relevant only for the inequalities. If you want the Î» for just the equalities, you can use <code>Î»[bounds.ceq] = Î»cE</code> for a zero-filled <code>Î»</code>.</p></div></div></section><pre><code class="language-none">Optim.x_abschange</code></pre><pre><code class="language-none">Optim.x_converged</code></pre><pre><code class="language-none">Optim.x_lower_trace</code></pre><pre><code class="language-none">Optim.x_tol</code></pre><pre><code class="language-none">Optim.x_trace</code></pre><pre><code class="language-none">Optim.x_upper_trace</code></pre><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Readme</span></a></footer></article></body></html>
